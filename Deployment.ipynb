{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbeb8390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "model_svc = pk.load(open('model.pkl', 'rb'))\n",
    "tv = pk.load(open('tv.pkl', 'rb'))\n",
    "lb = pk.load(open('lb.pkl', 'rb'))\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a72e36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "   \n",
    "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "def make_predictions(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    X = tv.transform([preprocessed_text]).toarray()\n",
    "    predicted_label = model_svc.predict(X)\n",
    "    confidence_scores = model_svc.predict_proba(X)\n",
    "    highest_score = confidence_scores.max()\n",
    "    if predicted_label[0] == 1:\n",
    "        prediction_label = 'valid'\n",
    "    else:\n",
    "        prediction_label = 'invalid'\n",
    "    return prediction_label, highest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c4ff239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: invalid\n",
      "Confidence Score: 0.9025941821981165\n"
     ]
    }
   ],
   "source": [
    "text_eg = '''hi accountid ade e ebfcbd e accountid f f c e f b fc c efd get event log kibana ship side howev get shore side caus data mismatch cm es pleas get check thank dev shore http comm kibana virginvoyag com goto b f c fa e bafa e f dev ship http comm kibana virginvoyag com goto ced cdad cd e f f f event log last day int shore http comm kibana virginvoyag com goto b ef b f ce int ship http comm kibana virginvoyag com goto cb fed c e cbe bf b event log last day cert shore http comm kibana virginvoyag com goto c c b f fe cert ship http comm kibana virginvoyag com goto c efffa fb bb b c b event log last day exampl shore razzl dazzl event json'''\n",
    "prediction_label, highest_score = make_predictions(text_eg)\n",
    "print(\"Predicted Label:\", prediction_label)\n",
    "print(\"Confidence Score:\", highest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673143a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
